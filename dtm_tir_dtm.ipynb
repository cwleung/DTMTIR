{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn7j4e7tN90e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUYiiIaGRaBS",
        "outputId": "495c51e9-4ad3-45a3-930f-410524287b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Feb 25 17:00:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-u04ZKTW0wR",
        "outputId": "c6b2fc79-7f65-459a-9f1f-131e6a511581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Downloading nips-papers-1987-2019-updated.zip to /content\n",
            " 96% 102M/106M [00:00<00:00, 197MB/s] \n",
            "100% 106M/106M [00:00<00:00, 240MB/s]\n",
            "Archive:  /content/nips-papers-1987-2019-updated.zip\n",
            "  inflating: authors.csv             \n",
            "  inflating: papers.csv              \n",
            "Downloading united-states-presidential-speeches.zip to /content\n",
            " 97% 21.0M/21.7M [00:00<00:00, 106MB/s]\n",
            "100% 21.7M/21.7M [00:00<00:00, 107MB/s]\n",
            "Archive:  /content/united-states-presidential-speeches.zip\n",
            "  inflating: corpus.csv              \n",
            "  inflating: fifth_party_corpus.csv  \n",
            "  inflating: first_party_corpus.csv  \n",
            "  inflating: fourth_party_corpus.csv  \n",
            "  inflating: presidential_speeches.csv  \n",
            "  inflating: second_party_corpus.csv  \n",
            "  inflating: sixth_party_corpus.csv  \n",
            "  inflating: third_party_corpus.csv  \n",
            "Downloading un-general-debates.zip to /content\n",
            " 96% 42.0M/43.6M [00:00<00:00, 151MB/s]\n",
            "100% 43.6M/43.6M [00:00<00:00, 214MB/s]\n",
            "Archive:  /content/un-general-debates.zip\n",
            "  inflating: un-general-debates.csv  \n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle                                               \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d rowhitswami/nips-papers-1987-2019-updated\n",
        "!unzip /content/nips-papers-1987-2019-updated.zip\n",
        "\n",
        "!kaggle datasets download -d littleotter/united-states-presidential-speeches\n",
        "!unzip /content/united-states-presidential-speeches.zip\n",
        "\n",
        "!kaggle datasets download -d unitednations/un-general-debates\n",
        "!unzip /content/un-general-debates.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "moUEBFujN90s",
        "outputId": "1a2474d7-7718-4339-cb8a-48faefac8115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.6.0.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Collecting torch\n",
            "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:41tcmalloc: large alloc 1147494400 bytes == 0x562a20f4c000 @  0x7f89e80ff615 0x562a1eba23bc 0x562a1ec8318a 0x562a1eba51cd 0x562a1ec97b3d 0x562a1ec19458 0x562a1ec1402f 0x562a1eba6aba 0x562a1ec192c0 0x562a1ec1402f 0x562a1eba6aba 0x562a1ec15cd4 0x562a1ec98986 0x562a1ec15350 0x562a1ec98986 0x562a1ec15350 0x562a1ec98986 0x562a1ec15350 0x562a1eba6f19 0x562a1ebeaa79 0x562a1eba5b32 0x562a1ec191dd 0x562a1ec1402f 0x562a1eba6aba 0x562a1ec15cd4 0x562a1ec1402f 0x562a1eba6aba 0x562a1ec14eae 0x562a1eba69da 0x562a1ec15108 0x562a1ec1402f\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 1.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Building wheels for collected packages: gpytorch\n",
            "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpytorch: filename=gpytorch-1.6.0-py2.py3-none-any.whl size=509889 sha256=85f89531f09dce23790c34341cc32296d2ff392754f99b043f46ead11476fcb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/b5/89/34c06ad393a6feb72b4cdde46d0f1c667f3e2632960f9df109\n",
            "Successfully built gpytorch\n",
            "Installing collected packages: torch, gpytorch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.10.2 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.10.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gpytorch-1.6.0 torch-1.10.2\n"
          ]
        }
      ],
      "source": [
        "#!CUDA_LAUNCH_BLOCKING=1\n",
        "!pip install gpytorch torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jHrzha8wN90u"
      },
      "outputs": [],
      "source": [
        "from gpytorch.models.gplvm.latent_variable import *\n",
        "from gpytorch.models.gplvm.bayesian_gplvm import BayesianGPLVM\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import trange\n",
        "from gpytorch.means import ZeroMean\n",
        "from gpytorch.mlls import VariationalELBO\n",
        "from gpytorch.priors import NormalPrior\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.variational import VariationalStrategy\n",
        "from gpytorch.variational import CholeskyVariationalDistribution,NaturalVariationalDistribution, TrilNaturalVariationalDistribution\n",
        "from gpytorch.kernels import ScaleKernel, RBFKernel,MaternKernel\n",
        "from gpytorch.distributions import MultivariateNormal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SndOf9WlUkew"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4EkPLJC7Ukez"
      },
      "outputs": [],
      "source": [
        "import gpytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import dtype, Tensor\n",
        "from torch.distributions.constraints import positive\n",
        "from torch.nn.modules.module import T\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Optional, Union, overload\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, num_topics, hidden, dropout, batchNorm):\n",
        "        super().__init__()\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "\n",
        "        self.num_topics = num_topics\n",
        "        self.batchNorm = batchNorm\n",
        "        self.drop = nn.Dropout(dropout)  # dropout\n",
        "        self.fc1 = nn.Linear(vocab_size+num_topics, hidden)\n",
        "        self.fc2 = nn.Linear(hidden+num_topics, hidden)\n",
        "        self.fcmu = nn.Linear(hidden+num_topics, num_topics, bias=True)  # fully-connected layer output mu\n",
        "        self.fclv = nn.Linear(hidden+num_topics, num_topics, bias=True)  # fully-connected layer output sigma\n",
        "        self.act1 = nn.Softplus()\n",
        "        self.act2 = nn.Softplus()\n",
        "        \n",
        "        self.norm1 = nn.LayerNorm(hidden, elementwise_affine=False)\n",
        "        self.norm2 = nn.LayerNorm(hidden, elementwise_affine=False)\n",
        "        \n",
        "        self.bnmu = nn.BatchNorm1d(num_topics, affine=False)  # to avoid component collapse\n",
        "        self.bnlv = nn.BatchNorm1d(num_topics, affine=False)  # to avoid component collapse\n",
        "\n",
        "        \n",
        "    def get_kl(self, q_mu, q_logsigma, p_mu=None, p_logsigma=None):\n",
        "        \"\"\" Gaussian KL Divergence\n",
        "        Returns KL( N(q_mu, q_logsigma) || N(p_mu, p_logsigma) ).\n",
        "        \"\"\"\n",
        "        if p_mu is not None and p_logsigma is not None:\n",
        "            sigma_q_sq = torch.exp(q_logsigma).to(device)\n",
        "            sigma_p_sq = torch.exp(p_logsigma).to(device)\n",
        "            kl = (sigma_q_sq + (q_mu - p_mu) ** 2) / (sigma_p_sq + 1e-6)\n",
        "            kl = kl - 1 + p_logsigma - q_logsigma\n",
        "            kl = 0.5 * torch.sum(kl, dim=-1).to(device)\n",
        "        else:\n",
        "            kl = -0.5 * torch.sum(1 + q_logsigma - q_mu.pow(2) - q_logsigma.exp(), dim=-1).to(device)\n",
        "        return kl\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar).to(device)\n",
        "        eps = torch.randn_like(std).to(device)\n",
        "        return eps.mul_(std).add_(mu)\n",
        "\n",
        "    def forward(self, inp, res_inp, eva=False):\n",
        "        inp = torch.cat([inp, res_inp], dim=1).to(device)\n",
        "        h = self.act1(self.fc1(inp))\n",
        "        h = self.norm1(h) # layernorm\n",
        "        inp = torch.cat([h, res_inp], dim=1).to(device)\n",
        "        h = self.act2(self.fc2(inp))\n",
        "        h = self.norm2(h) # layernorm\n",
        "        h = self.drop(h)\n",
        "        h = torch.cat([h, res_inp], dim=1).to(device)\n",
        "        # μ and Σ are two inference networks\n",
        "        mu_theta = self.fcmu(h)\n",
        "        sig_theta = self.fclv(h)\n",
        "        if eva:\n",
        "            return mu_theta.softmax(-1)\n",
        "        z = self.reparameterize(mu_theta, sig_theta)\n",
        "        theta = torch.softmax(z, -1).to(device)\n",
        "        kld_theta = self.get_kl(mu_theta, sig_theta, res_inp, 0.005*torch.randn(self.num_topics).to(device))\n",
        "        return theta, kld_theta\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # Pre-trained embedding, alpha, rho, embedding method\n",
        "    # Need to be refactored with Topic Embedding\n",
        "    def __init__(self, vocab_size, num_topics, num_times, dropout,\n",
        "                 useEmbedding=True, rho_size=256, pre_embedding=None, emb_type='NN',\n",
        "                 trainEmbedding=True):\n",
        "        super().__init__()\n",
        "        # this beta can be refactorized in to BOW, a neural network that to be trained\n",
        "        self.emb_type = emb_type\n",
        "        self.trainEmbedding = trainEmbedding\n",
        "        self.useEmbedding = useEmbedding\n",
        "        self.rho_size = rho_size\n",
        "        # Changes - Beta\n",
        "        # < Linear NN (K->V)\n",
        "        # > Embedding -> Linear NN (K->E->V)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        if self.useEmbedding:\n",
        "            # Call ρ Topic Embedding\n",
        "\n",
        "            if trainEmbedding:\n",
        "                self.fcrho = TopicEmbedding(rho_size, vocab_size, pre_embedding,\n",
        "                                            emb_type, dropout)\n",
        "                self.bnrho = nn.BatchNorm1d(rho_size, affine=False)\n",
        "            # use original embedding\n",
        "            else:\n",
        "                self.fcrho = TopicEmbedding(rho_size, vocab_size, pre_embedding,\n",
        "                                            emb_type, dropout, trans_layer, trans_head, trans_dim)\n",
        "            # Call α\n",
        "            self.fcalpha = nn.Linear(rho_size, num_topics, bias=False)\n",
        "            self.bnalpha = nn.BatchNorm1d(num_topics, affine=False)\n",
        "            # nn.Parameter(torch.randn(rho_size, num_topics))\n",
        "        else:\n",
        "            # Call β, Use Original NN (K->V)\n",
        "            self.fcbeta = nn.Parameter(torch.randn(num_times, num_topics, vocab_size).to(device))\n",
        "            #self.bnbeta = nn.BatchNorm1d(vocab_size, affine=False)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(vocab_size, affine=False)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "            \n",
        "    def get_beta(self, alpha):\n",
        "        if self.trainEmbedding:\n",
        "            if self.emb_type is 'NN':\n",
        "#                 logit = self.fcrho(alpha.reshape(alpha.size(0) * alpha.size(1), self.rho_size))\n",
        "#                 logit = logit.reshape(alpha.size(0), alpha.size(1), -1)\n",
        "#                 beta = F.softmax(logit, dim=-1)\n",
        "                n_alpha = alpha.reshape(alpha.size(0) * alpha.size(1), self.rho_size)\n",
        "                rho = self.fcrho.rho.weight.T\n",
        "                logit = torch.mm(n_alpha, rho)\n",
        "                logit = logit.reshape(alpha.size(0), alpha.size(1), -1)\n",
        "                beta = F.softmax(logit, dim=-1)\n",
        "            else:\n",
        "                raise ValueError('Wrong embedding type')\n",
        "        elif self.useEmbedding:\n",
        "            beta = self.bnalpha(self.fcalpha(self.bnrho(self.fcrho.weight()))).transpose(1, 0).to(device)\n",
        "        else:\n",
        "            beta = self.fcbeta.weight\n",
        "        return beta\n",
        "\n",
        "\n",
        "class TopicEmbedding(nn.Module):\n",
        "    def __init__(self, rho_size, vocab_size, pre_embedding=None,\n",
        "                 emb_type='NN', dropout=0.0,\n",
        "                 n_heads=8, n_layer=4, n_dim=128, n_code=8):\n",
        "        super().__init__()\n",
        "        self.emb_type = emb_type\n",
        "        if pre_embedding is None:\n",
        "            # 1. Embedding layer\n",
        "            if emb_type is 'NN':\n",
        "                self.rho = nn.Linear(rho_size, vocab_size, bias=False)\n",
        "            else:\n",
        "                raise ValueError('Wrong Embedding Type')\n",
        "        else:\n",
        "            self.rho = pre_embedding.clone().float().to(device)\n",
        "            \n",
        "    def forward(self, inputs):\n",
        "        if self.emb_type is 'NN':\n",
        "            return self.rho(inputs)\n",
        "        else:\n",
        "            raise ValueError('Wrong Embedding Type')\n",
        "\n",
        "\n",
        "class TETM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, num_topics, num_times, hidden, dropout,\n",
        "                 delta, data_size, useEmbedding=False, eta_size=256, rho_size=256,\n",
        "                 pre_embedding=None, emb_type='NN', trainEmbedding=False, batchNorm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.delta = delta\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_topics = num_topics\n",
        "        self.num_times = num_times\n",
        "        self.useEmbedding = useEmbedding\n",
        "        self.emb_type = emb_type\n",
        "        self.rho_size = rho_size\n",
        "        self.eta_size = eta_size\n",
        "\n",
        "        self.encoder = Encoder(vocab_size, num_topics, hidden, dropout, batchNorm).to(device)\n",
        "        self.decoder = Decoder(vocab_size, num_topics, num_times,dropout,\n",
        "                               useEmbedding, rho_size, pre_embedding, emb_type,\n",
        "                               trainEmbedding).to(device)\n",
        "        ## define the variational parameters for the topic embeddings over time (alpha) ... alpha is K x T x L\n",
        "        self.mu_q_alpha = nn.Parameter(torch.randn(num_topics, num_times, rho_size).to(device))\n",
        "        self.logsigma_q_alpha = nn.Parameter(torch.randn(num_topics, num_times, rho_size).to(device))\n",
        "\n",
        "        self.data_size = data_size\n",
        "        self.gplvm = bGPLVM(self.data_size, vocab_size, self.num_topics, 100).to(device)\n",
        "        self.likelihood = GaussianLikelihood(batch_shape=(num_times, vocab_size)).to(device)\n",
        "        \n",
        "        self.mu_q_eta = nn.Linear(self.num_topics, self.num_topics, bias=True).to(device)\n",
        "        self.logsigma_q_eta = nn.Linear(self.num_topics, self.num_topics, bias=True).to(device)\n",
        "\n",
        "        self.eta = nn.Parameter(torch.randn(self.num_times,self.num_topics).to(device))\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar).to(device)\n",
        "        eps = torch.randn_like(std).to(device)\n",
        "        return eps.mul_(std).add_(mu)\n",
        "\n",
        "    def get_beta(self,alpha):\n",
        "        beta = self.decoder.get_beta(alpha)\n",
        "        return beta\n",
        "    \n",
        "    def get_theta(self, eta, bows, times):\n",
        "        eta_td = eta[times.type('torch.LongTensor')]\n",
        "        theta, kl_theta = self.encoder(bows, eta_td)\n",
        "        return theta, kl_theta\n",
        "\n",
        "    def decode(self, theta, beta):\n",
        "        res = torch.mm(theta, beta)\n",
        "        preds = torch.log(res + 1e-6)\n",
        "        return preds\n",
        "\n",
        "    def get_kl(self, q_mu, q_logsigma, p_mu=None, p_logsigma=None):\n",
        "        \"\"\" Gaussian KL Divergence\n",
        "        Returns KL( N(q_mu, q_logsigma) || N(p_mu, p_logsigma) ).\n",
        "        \"\"\"\n",
        "        if p_mu is not None and p_logsigma is not None:\n",
        "            sigma_q_sq = torch.exp(q_logsigma).to(device)\n",
        "            sigma_p_sq = torch.exp(p_logsigma).to(device)\n",
        "            kl = (sigma_q_sq + (q_mu - p_mu) ** 2) / (sigma_p_sq + 1e-6)\n",
        "            kl = kl - 1 + p_logsigma - q_logsigma\n",
        "            kl = 0.5 * torch.sum(kl, dim=-1).to(device)\n",
        "        else:\n",
        "            kl = -0.5 * torch.sum(1 + q_logsigma - q_mu.pow(2) - q_logsigma.exp(), dim=-1).to(device)\n",
        "        return kl\n",
        "        \n",
        "    def get_alpha(self):  ## mean field\n",
        "        # TxKxL\n",
        "        alphas = torch.zeros(self.num_times, self.num_topics, self.rho_size).to(device)\n",
        "        kl_alpha = []\n",
        "        alphas[0] = self.reparameterize(self.mu_q_alpha[:, 0, :], self.logsigma_q_alpha[:, 0, :])\n",
        "        p_mu_0 = torch.zeros(self.num_topics, self.rho_size).to(device)\n",
        "        logsigma_p_0 = torch.zeros(self.num_topics, self.rho_size).to(device)\n",
        "        kl_0 = self.get_kl(self.mu_q_alpha[:, 0, :], self.logsigma_q_alpha[:, 0, :], p_mu_0, logsigma_p_0)\n",
        "        kl_alpha.append(kl_0)\n",
        "        for t in range(1, self.num_times):\n",
        "            alphas[t] = self.reparameterize(self.mu_q_alpha[:, t, :], self.logsigma_q_alpha[:, t, :])\n",
        "            p_mu_t = alphas[t - 1]\n",
        "            logsigma_p_t = torch.log(self.delta * torch.ones(self.num_topics, self.rho_size).to(device))\n",
        "            kl_t = self.get_kl(self.mu_q_alpha[:, t, :], self.logsigma_q_alpha[:, t, :], p_mu_t, logsigma_p_t)\n",
        "            kl_alpha.append(kl_t)\n",
        "        kl_alpha = torch.stack(kl_alpha).sum()\n",
        "        return alphas, kl_alpha.sum()\n",
        "\n",
        "    # Compute η[t]~N(η[t-1], δ^2*I), η[0]=\n",
        "    def get_eta(self, eta_inp):\n",
        "        etas = torch.zeros(self.num_times, self.num_topics).to(device)\n",
        "        kl_eta = []\n",
        "        inp_0 = eta_inp[0]#torch.cat([eta_inp[0], torch.zeros(self.num_topics, ).to(device)], dim=0).to(device)\n",
        "        mu_0, logsigma_0 = self.mu_q_eta(inp_0), self.logsigma_q_eta(inp_0)\n",
        "        etas[0] = self.reparameterize(mu_0, logsigma_0)\n",
        "        p_mu_0, logsigma_p_0 = torch.zeros(self.num_topics, ).to(device), torch.zeros(self.num_topics, ).to(device)\n",
        "        kl_0 = self.get_kl(mu_0, logsigma_0, p_mu_0, logsigma_p_0)\n",
        "        kl_eta.append(kl_0)\n",
        "        for t in range(1, self.num_times):\n",
        "            inp_t = eta_inp[t]#torch.cat([eta_inp[t], etas[t - 1]], dim=0)\n",
        "            mu_t, logsigma_t = self.mu_q_eta(inp_t), self.logsigma_q_eta(inp_t)\n",
        "            etas[t] = self.reparameterize(mu_t, logsigma_t)\n",
        "            logsigma_p_t = torch.log(self.delta * torch.ones(self.num_topics,).to(device))\n",
        "            kl_t = self.get_kl(mu_t, logsigma_t, etas[t - 1], logsigma_p_t)\n",
        "            kl_eta.append(kl_t)\n",
        "        kl_eta = torch.stack(kl_eta).sum()\n",
        "        return etas, kl_eta\n",
        "\n",
        "    def init_hidden(self):\n",
        "        \"\"\"Initializes the first hidden state of the RNN used as inference network for \\eta.\n",
        "        \"\"\"\n",
        "        weight = next(self.parameters())\n",
        "        nlayers = self.eta_nlayers\n",
        "        nhid = self.eta_size\n",
        "        return (weight.new_zeros(nlayers, 1, nhid), weight.new_zeros(nlayers, 1, nhid))\n",
        "    \n",
        "    def get_mu(self, rnn_inp):\n",
        "        mll = VariationalELBO(self.likelihood, self.gplvm, num_data=len(rnn_inp))#,combine_terms=False)\n",
        "        sample = self.gplvm.sample_latent_variable()\n",
        "        output = self.gplvm(sample)\n",
        "        loss = mll(output, rnn_inp.T.to(device))\n",
        "        # nll + kl_x + kl_u\n",
        "        return self.gplvm.X.q_mu, loss#loss[0].sum()+loss[1].sum()+loss[2].sum()+loss[3].sum()\n",
        "\n",
        "    def forward(self, bows, norm_bows, times, rnn_inp, num_docs):\n",
        "        bsz = bows.size(0)\n",
        "        coeff = num_docs / bsz\n",
        "        #eta, kl_eta = self.get_eta(rnn_inp)\n",
        "        #eta_gp, kld_eta_gp = self.get_mu(rnn_inp)\n",
        "        kld_eta = torch.zeros(()).to(device)\n",
        "        #eta, kld_eta = self.get_eta(eta_gp.to(device))\n",
        "        # get theta N(η,α^2I)\n",
        "        theta, kld_theta = self.get_theta(self.eta, norm_bows, times)\n",
        "        kld_theta = kld_theta.sum() * coeff\n",
        "        alpha, kl_alpha = self.get_alpha()\n",
        "        assert (alpha.shape == torch.Size(\n",
        "            [self.num_times, self.num_topics, self.rho_size]\n",
        "        ))\n",
        "        beta = self.get_beta(alpha)\n",
        "        beta = beta[times.type('torch.LongTensor')]\n",
        "\n",
        "        assert (beta.shape == torch.Size(\n",
        "            [bows.shape[0], self.num_topics, self.vocab_size]\n",
        "        ))\n",
        "        theta = theta.unsqueeze(1)\n",
        "        assert (theta.shape == torch.Size([bows.shape[0], 1, self.num_topics]\n",
        "                                        ))\n",
        "        pred = torch.bmm(theta, beta).squeeze(1).nan_to_num()\n",
        "        logp = torch.log(pred + 1e-6).nan_to_num()\n",
        "        nll = -(logp * bows).sum(-1)\n",
        "        nll = nll.sum() * coeff\n",
        "        return nll, kl_alpha, kld_eta, kld_theta ,0#kld_eta_gp\n",
        "    \n",
        "    def get_beta_result(self):\n",
        "        alpha = model.mu_q_alpha.clone().contiguous()\n",
        "        alpha = alpha.permute(1,0,2)\n",
        "        beta = model.get_beta(alpha, torch.arange(0,ts.unique().shape[0]))\n",
        "        return beta\n",
        "    \n",
        "    def get_eta_result(self):\n",
        "        return self.gplvm.X.q_mu\n",
        "\n",
        "    def predict(self, d_bat, norm_d_bat, t_bat, rnn_inp):\n",
        "        \"\"\"give out the test data set, return the corresponding perplexity\"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # get eta(TxK)\n",
        "            #eta = self.gplvm.X.q_mu\n",
        "            eta = self.eta\n",
        "            #eta, kl_eta = self.get_eta(rnn_inp)\n",
        "            assert (eta.shape == torch.Size([self.num_times, self.num_topics]))\n",
        "            # get theta(DxK)\n",
        "            eta_td = eta[t_bat.type('torch.LongTensor')]\n",
        "            theta = self.encoder(d_bat, eta_td,eva=True)\n",
        "            #theta = self.get_theta(eta, norm_d_bat, t_bat)[0]\n",
        "            assert (theta.shape == torch.Size([norm_d_bat.shape[0], self.num_topics]))\n",
        "            #theta = theta.unsqueeze(1)\n",
        "            # get alpha(KxTxL)\n",
        "            alpha = model.mu_q_alpha.clone().contiguous()\n",
        "            #alpha = alpha.permute(1, 0, 2)\n",
        "            assert (alpha.shape == torch.Size(\n",
        "                [self.num_topics, self.num_times, self.rho_size]\n",
        "            ))\n",
        "            # alpha_td(KxDxL)\n",
        "            #alpha_td = alpha[:,t_bat.type('torch.LongTensor'), :]\n",
        "#             assert (alpha_td.shape == torch.Size(\n",
        "#                 [self.num_topics, d_bat.shape[0], self.rho_size]\n",
        "#             ))\n",
        "            # get beta(T[D]xKxV)\n",
        "            beta = self.get_beta(alpha)\n",
        "            beta = beta.permute(1, 0, 2)\n",
        "            beta = beta[t_bat.type('torch.LongTensor')]\n",
        "            assert (beta.shape == torch.Size(\n",
        "                [d_bat.shape[0], self.num_topics, self.vocab_size]\n",
        "            ))\n",
        "            loglik = theta.unsqueeze(2) * beta\n",
        "            pred = loglik.sum(1)\n",
        "            #pred = torch.bmm(theta, beta).squeeze(1)\n",
        "            logp = torch.log(pred)\n",
        "            sums = d_bat.sum(1).unsqueeze(1)\n",
        "            loss = (-logp * d_bat).sum(-1) / sums.squeeze()\n",
        "            loss = loss.nan_to_num().mean().item()\n",
        "            # ppl check when doing mini-batch\n",
        "            ppl = round(math.exp(loss), 1)\n",
        "            return ppl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mmXGNZ9ySqv5"
      },
      "outputs": [],
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d2kaWE1AN91P"
      },
      "outputs": [],
      "source": [
        "class bGPLVM(BayesianGPLVM):\n",
        "    def __init__(self, n, data_dim, latent_dim, n_inducing, pca=False, nu=2.5):\n",
        "        self.n = n\n",
        "        self.batch_shape = torch.Size([data_dim])\n",
        "        self.inducing_inputs = torch.randn(data_dim, n_inducing, latent_dim).to(device)\n",
        "        q_u = CholeskyVariationalDistribution(n_inducing)\n",
        "        q_f = VariationalStrategy(self, self.inducing_inputs, q_u, learn_inducing_locations=True)\n",
        "        X_prior_mean = torch.zeros(n, latent_dim).to(device)  # shape: N x Q\n",
        "        prior_x = NormalPrior(X_prior_mean, torch.ones_like(X_prior_mean).to(device))\n",
        "        X_init = torch.nn.Parameter(torch.randn(n, latent_dim))\n",
        "        # LatentVariable (c)\n",
        "        X = VariationalLatentVariable(n, data_dim, latent_dim, X_init, prior_x)\n",
        "        super().__init__(X, q_f)\n",
        "        self.mean_module = ZeroMean(ard_num_dims=latent_dim)\n",
        "        self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=latent_dim))\n",
        "        init_lengthscale = 0.1\n",
        "        self.covar_module.base_kernel.lengthscale = init_lengthscale\n",
        "\n",
        "    def forward(self, X):\n",
        "        mean_x = self.mean_module(X)\n",
        "        covar_x = self.covar_module(X)\n",
        "        dist = MultivariateNormal(mean_x, covar_x)\n",
        "        return dist\n",
        "\n",
        "    def _get_batch_idx(self, batch_size):\n",
        "        valid_indices = np.arange(self.n)\n",
        "        batch_indices = np.random.choice(valid_indices, size=batch_size, replace=False)\n",
        "        return np.sort(batch_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6s7SepmCN91U"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import torch \n",
        "import numpy as np\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "def get_df(data, wi, wj=None):\n",
        "    \"\"\"\n",
        "    Obtain the document frequency\n",
        "    :param data: document vocabulary matrix\n",
        "    :param wi: word index w_i\n",
        "    :param wj: word index w_j\n",
        "    :return: document frequency for word w_i , w_i ∩ w_j\n",
        "    \"\"\"\n",
        "    if wj is None:\n",
        "        return torch.where(data[:, wi] > 0, 1, 0).sum(-1)\n",
        "    else:\n",
        "        df_wi = torch.where(data[:, wi] > 0, 1, 0)\n",
        "        df_wj = torch.where(data[:, wj] > 0, 1, 0)\n",
        "        return df_wj.sum(-1), (df_wi & df_wj).sum(-1)\n",
        "\n",
        "\n",
        "def get_topic_coherence(beta, data):\n",
        "    D = torch.tensor(len(data)) ## number of docs...data is list of documents\n",
        "    TC = []\n",
        "    num_topics = len(beta)\n",
        "    counter = 0\n",
        "    for k in range(num_topics):\n",
        "        top_10 = list(torch.flip(beta[k].argsort()[-11:],[0]))\n",
        "        TC_k = 0\n",
        "        counter = 0\n",
        "        for i, word in enumerate(top_10):\n",
        "            D_wi = get_df(data, word)\n",
        "            j = i + 1\n",
        "            tmp = 0\n",
        "            while j < len(top_10) and j > i:\n",
        "                D_wj, D_wi_wj = get_df(data, word, top_10[j])\n",
        "                if D_wi_wj == 0:\n",
        "                    f_wi_wj = -1\n",
        "                else:\n",
        "                    f_wi_wj = -1 + (torch.log(D_wi)+torch.log(D_wj)-2.0*torch.log(D))/(torch.log(D_wi_wj)-torch.log(D))\n",
        "                tmp += f_wi_wj\n",
        "                j += 1\n",
        "                counter += 1\n",
        "            TC_k += tmp \n",
        "        TC.append(TC_k.detach().cpu().numpy())\n",
        "    TC = np.mean(TC) / counter\n",
        "    #print('Topic coherence is: {}'.format(TC))\n",
        "    return TC\n",
        "\n",
        "\n",
        "def visualize(docs, _lda_keys, topics, theta):\n",
        "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
        "    # project to 2D\n",
        "    tsne_lda = tsne_model.fit_transform(theta)\n",
        "    colormap = []\n",
        "    for name, hex in matplotlib.colors.cnames.items():\n",
        "        colormap.append(hex)\n",
        "\n",
        "    colormap = colormap[:len(theta[0, :])]\n",
        "    colormap = np.array(colormap)\n",
        "\n",
        "    title = '20 newsgroups TE embedding V viz'\n",
        "    num_example = len(docs)\n",
        "\n",
        "    plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
        "                     title=title,\n",
        "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
        "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
        "\n",
        "    plt.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
        "                 color=colormap[_lda_keys][:num_example])\n",
        "    plt.show()\n",
        "\n",
        "def get_rnn_inp(data_batch,times_batch, num_times, vocab_size):\n",
        "    rnn_input = torch.zeros(num_times, vocab_size).to(device)\n",
        "    cnt = torch.zeros(num_times, ).to(device)\n",
        "    for t in range(num_times):\n",
        "        tmp = (times_batch == t).nonzero()\n",
        "        docs = data_batch[tmp].squeeze().sum(0)\n",
        "        rnn_input[t] += docs\n",
        "        cnt[t] += tmp.shape[0]\n",
        "    rnn_input = rnn_input / cnt.unsqueeze(1)\n",
        "    return rnn_input\n",
        "    \n",
        "    \n",
        "# def get_rnn_input(dataloader, num_times, vocab_size):\n",
        "#     # TxV\n",
        "#     rnn_input = torch.zeros(num_times, vocab_size).to(device)\n",
        "#     # times count\n",
        "#     cnt = torch.zeros(num_times, ).to(device)\n",
        "#     # create data loader\n",
        "#     for data in dataloader:\n",
        "#         data_batch = cvz[data['index'].long() - 1,:].to(device)\n",
        "#         times_batch = ts[data['index'].long() - 1].to(device)\n",
        "#         for t in range(num_times):\n",
        "#             # check times\n",
        "#             tmp = (times_batch == t).nonzero()\n",
        "#             # sum the vocabulary in time t\n",
        "#             docs = data_batch[tmp].squeeze().sum(0)\n",
        "#             # feed in the vocabulary count in time t\n",
        "#             rnn_input[t] += docs\n",
        "#             # sum up the count\n",
        "#             cnt[t] += tmp.shape[0]\n",
        "#             # check the epoch\n",
        "#     rnn_input = rnn_input / cnt.unsqueeze(1)\n",
        "#     return rnn_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w3nDgR7WN91W",
        "outputId": "6f531b0c-8004-4a0d-e784-6811d2597c14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total document 991\n",
            "counting document frequency of words...\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "import string\n",
        "from tqdm import trange\n",
        "from scipy import sparse\n",
        "from scipy.io import savemat, loadmat\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Maximum / minimum document frequency\n",
        "max_df = 0.5\n",
        "min_df = 100  # choose desired value for min_df\n",
        "\n",
        "# read data\n",
        "# # un debates\n",
        "# data = pd.read_csv('/content/un-general-debates.csv')\n",
        "# data = data[['session', 'year', 'country', 'text']]\n",
        "# data.sort_values('year', ascending=True, inplace=True)\n",
        "# docs = data.text.to_numpy()  ## bows\n",
        "# neurips\n",
        "# data = pd.read_csv('/content/papers.csv')\n",
        "# data = data[~data.full_text.isnull()]\n",
        "# docs = data.full_text.values  ## bows\n",
        "# data.sort_values('year', ascending=True, inplace=True)\n",
        "# US-Presidental Speeches\n",
        "data = pd.read_csv('/content/presidential_speeches.csv')\n",
        "data.sort_values('Date', ascending=True, inplace=True)\n",
        "data = data[~data.Transcript.isnull()]\n",
        "docs = data.Transcript.values\n",
        "data['year']= pd.to_datetime(data.Date).dt.year\n",
        "\n",
        "# unique timestamp\n",
        "times = data.year.unique()\n",
        "times.sort()\n",
        "\n",
        "# timestamp input\n",
        "ts = torch.from_numpy(data.year.to_numpy()).to(device)  ## timestamp\n",
        "ts = (ts==ts.unique()[:,None]).nonzero().transpose(1,0)[0].to(device)\n",
        "timestamps = data.year.values\n",
        "# Read stopwords\n",
        "with open('/content/stops.txt', 'r') as f:\n",
        "    stops = f.read().split('\\n')\n",
        "    \n",
        "print(f'Total document {len(docs)}')\n",
        "#times_rank = (torch.tensor(ts)==torch.from_numpy(np.unique(ts))[:,None]).nonzero().T[0,:]\n",
        "\n",
        "# Create count vectorizer\n",
        "print('counting document frequency of words...')\n",
        "\n",
        "def contains_punctuation(w):\n",
        "    return any(char in string.punctuation for char in w)\n",
        "\n",
        "def contains_numeric(w):\n",
        "    return any(char.isdigit() for char in w)\n",
        "\n",
        "# document preprocessing\n",
        "init_docs = [re.findall(r'''[\\w']+|[.,!?;-~{}`´_<=>:/@*()&'$%#\"]|[\\n]+''', doc) for doc in docs]\n",
        "init_docs = [[w.lower() for w in init_docs[doc] if not contains_punctuation(w)] for doc in range(len(init_docs))]\n",
        "init_docs = [[w for w in init_docs[doc] if not contains_numeric(w)] for doc in range(len(init_docs))]\n",
        "init_docs = [[w for w in init_docs[doc] if len(w) > 1] for doc in range(len(init_docs))]\n",
        "init_docs = [\" \".join(init_docs[doc]) for doc in range(len(init_docs))]\n",
        "\n",
        "# cvectorizer = CountVectorizer(min_df=min_df, max_df=max_df, stop_words=frozenset(stops))\n",
        "\n",
        "# cvz = cvectorizer.fit_transform(init_docs)#.sign()\n",
        "# cvz = torch.from_numpy(cvz.todense())\n",
        "\n",
        "#print(f'documents={cvz.shape[0]};vocabulary={cvz.shape[1]};tokens={cvz.sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a7661SwsUkfD",
        "outputId": "a4a18fb1-0e3e-4f4c-c437-ec360bbc7701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading raw data...\n",
            "counting document frequency of words...\n",
            "building the vocabulary...\n",
            "  initial vocabulary size: 1891\n",
            "  vocabulary size after removing stopwords from list: 1891\n",
            "tokenizing documents and splitting into train/test/valid...\n",
            "  vocabulary after removing words not in train: 1891\n",
            "  number of documents (train): 792 [this should be equal to 792 and 792]\n",
            "  number of documents (test): 148 [this should be equal to 148 and 148]\n",
            "  number of documents (valid): 51 [this should be equal to 51 and 51]\n",
            "removing empty documents...\n",
            "splitting test documents in 2 halves...\n",
            "creating lists of words...\n",
            "  len(words_tr):  495683\n",
            "  len(words_ts):  83149\n",
            "  len(words_ts_h1):  41536\n",
            "  len(words_ts_h2):  41613\n",
            "  len(words_va):  26589\n",
            "getting doc indices...\n",
            "  len(np.unique(doc_indices_tr)): 792 [this should be 792]\n",
            "  len(np.unique(doc_indices_ts)): 148 [this should be 148]\n",
            "  len(np.unique(doc_indices_ts_h1)): 148 [this should be 148]\n",
            "  len(np.unique(doc_indices_ts_h2)): 148 [this should be 148]\n",
            "  len(np.unique(doc_indices_va)): 51 [this should be 51]\n",
            "creating bow representation...\n",
            "saving LDA files for C++ code...\n",
            "splitting bow intro token/value pairs and saving to disk...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:450: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  narr = np.asanyarray(source)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data ready !!\n",
            "*************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Read raw data\n",
        "print('reading raw data...')\n",
        "# docs = []\n",
        "# not_found = []\n",
        "# timestamps = []\n",
        "# for (pid, tt) in zip(all_pids, all_timestamps):\n",
        "#     path_read = 'raw/acl_abstracts/acl_data-combined/all_papers'\n",
        "#     path_read = os.path.join(path_read, pid + '.txt')\n",
        "#     if not os.path.isfile(path_read):\n",
        "#         not_found.append(pid)\n",
        "#     else:\n",
        "#         with open(path_read, 'rb') as f:\n",
        "#             doc = f.read().decode('utf-8', 'ignore')\n",
        "#             doc = doc.lower().replace('\\n', ' ').replace(\"’\", \" \").replace(\"'\", \" \").translate(str.maketrans(string.punctuation + \"0123456789\", ' '*len(string.punctuation + \"0123456789\"))).split()\n",
        "#         doc = [remove_not_printable(w) for w in doc if len(w)>1]\n",
        "#         if len(doc) > 1:\n",
        "#             doc = \" \".join(doc)\n",
        "#             docs.append(doc)\n",
        "#             timestamps.append(tt)\n",
        "\n",
        "# Write as raw text\n",
        "# print('writing to text file...')\n",
        "# out_filename = './docs_processed.txt'\n",
        "# print('writing to text file...')\n",
        "# with open(out_filename, 'w') as f:\n",
        "#     for line in docs:\n",
        "#         f.write(line + '\\n')\n",
        "\n",
        "# Read stopwords\n",
        "# with open('../input/stopwords/stops.txt', 'r') as f:\n",
        "#     stops = f.read().split('\\n')\n",
        "\n",
        "# Create count vectorizer\n",
        "print('counting document frequency of words...')\n",
        "cvectorizer = CountVectorizer(min_df=min_df, max_df=max_df, stop_words=frozenset(stops))\n",
        "cvz = cvectorizer.fit_transform(init_docs).sign()\n",
        "\n",
        "# Get vocabulary\n",
        "print('building the vocabulary...')\n",
        "sum_counts = cvz.sum(axis=0)\n",
        "v_size = sum_counts.shape[1]\n",
        "sum_counts_np = np.zeros(v_size, dtype=int)\n",
        "for v in range(v_size):\n",
        "    sum_counts_np[v] = sum_counts[0,v]\n",
        "word2id = dict([(w, cvectorizer.vocabulary_.get(w)) for w in cvectorizer.vocabulary_])\n",
        "id2word = dict([(cvectorizer.vocabulary_.get(w), w) for w in cvectorizer.vocabulary_])\n",
        "#del cvectorizer\n",
        "print('  initial vocabulary size: {}'.format(v_size))\n",
        "\n",
        "# Sort elements in vocabulary\n",
        "idx_sort = np.argsort(sum_counts_np)\n",
        "vocab_aux = [id2word[idx_sort[cc]] for cc in range(v_size)]\n",
        "\n",
        "# Filter out stopwords (if any)\n",
        "vocab_aux = [w for w in vocab_aux if w not in stops]\n",
        "print('  vocabulary size after removing stopwords from list: {}'.format(len(vocab_aux)))\n",
        "\n",
        "# Create dictionary and inverse dictionary\n",
        "vocab = vocab_aux\n",
        "del vocab_aux\n",
        "word2id = dict([(w, j) for j, w in enumerate(vocab)])\n",
        "id2word = dict([(j, w) for j, w in enumerate(vocab)])\n",
        "\n",
        "# Create mapping of timestamps\n",
        "all_times = sorted(set(timestamps))\n",
        "time2id = dict([(t, i) for i, t in enumerate(all_times)])\n",
        "id2time = dict([(i, t) for i, t in enumerate(all_times)])\n",
        "time_list = [id2time[i] for i in range(len(all_times))]\n",
        "\n",
        "# Split in train/test/valid\n",
        "print('tokenizing documents and splitting into train/test/valid...')\n",
        "num_docs = cvz.shape[0]\n",
        "trSize = int(np.floor(0.8*num_docs))\n",
        "tsSize = int(np.floor(0.15*num_docs))\n",
        "vaSize = int(num_docs - trSize - tsSize)\n",
        "#del cvz\n",
        "idx_permute = np.random.permutation(num_docs).astype(int)\n",
        "\n",
        "# Remove words not in train_data\n",
        "# vocab = list(set([w for idx_d in range(trSize) for w in docs[idx_permute[idx_d]].split() if w in word2id]))\n",
        "# word2id = dict([(w, j) for j, w in enumerate(vocab)])\n",
        "# id2word = dict([(j, w) for j, w in enumerate(vocab)])\n",
        "print('  vocabulary after removing words not in train: {}'.format(len(vocab)))\n",
        "\n",
        "docs_tr = [[word2id[w] for w in docs[idx_permute[idx_d]].split() if w in word2id] for idx_d in range(trSize)]\n",
        "timestamps_tr = [time2id[timestamps[idx_permute[idx_d]]] for idx_d in range(trSize)]\n",
        "docs_ts = [[word2id[w] for w in docs[idx_permute[idx_d+trSize]].split() if w in word2id] for idx_d in range(tsSize)]\n",
        "timestamps_ts = [time2id[timestamps[idx_permute[idx_d+trSize]]] for idx_d in range(tsSize)]\n",
        "docs_va = [[word2id[w] for w in docs[idx_permute[idx_d+trSize+tsSize]].split() if w in word2id] for idx_d in range(vaSize)]\n",
        "timestamps_va = [time2id[timestamps[idx_permute[idx_d+trSize+tsSize]]] for idx_d in range(vaSize)]\n",
        "\n",
        "print('  number of documents (train): {} [this should be equal to {} and {}]'.format(len(docs_tr), trSize, len(timestamps_tr)))\n",
        "print('  number of documents (test): {} [this should be equal to {} and {}]'.format(len(docs_ts), tsSize, len(timestamps_ts)))\n",
        "print('  number of documents (valid): {} [this should be equal to {} and {}]'.format(len(docs_va), vaSize, len(timestamps_va)))\n",
        "\n",
        "# Remove empty documents\n",
        "print('removing empty documents...')\n",
        "\n",
        "def remove_empty(in_docs, in_timestamps):\n",
        "    out_docs = []\n",
        "    out_timestamps = []\n",
        "    for ii, doc in enumerate(in_docs):\n",
        "        if(doc!=[]):\n",
        "            out_docs.append(doc)\n",
        "            out_timestamps.append(in_timestamps[ii])\n",
        "    return out_docs, out_timestamps\n",
        "\n",
        "def remove_by_threshold(in_docs, in_timestamps, thr):\n",
        "    out_docs = []\n",
        "    out_timestamps = []\n",
        "    for ii, doc in enumerate(in_docs):\n",
        "        if(len(doc)>thr):\n",
        "            out_docs.append(doc)\n",
        "            out_timestamps.append(in_timestamps[ii])\n",
        "    return out_docs, out_timestamps\n",
        "\n",
        "docs_tr, timestamps_tr = remove_empty(docs_tr, timestamps_tr)\n",
        "docs_ts, timestamps_ts = remove_empty(docs_ts, timestamps_ts)\n",
        "docs_va, timestamps_va = remove_empty(docs_va, timestamps_va)\n",
        "\n",
        "# Remove test documents with length=1\n",
        "docs_ts, timestamps_ts = remove_by_threshold(docs_ts, timestamps_ts, 1)\n",
        "\n",
        "# Split test set in 2 halves\n",
        "print('splitting test documents in 2 halves...')\n",
        "docs_ts_h1 = [[w for i,w in enumerate(doc) if i<=len(doc)/2.0-1] for doc in docs_ts]\n",
        "docs_ts_h2 = [[w for i,w in enumerate(doc) if i>len(doc)/2.0-1] for doc in docs_ts]\n",
        "\n",
        "# Getting lists of words and doc_indices\n",
        "print('creating lists of words...')\n",
        "\n",
        "def create_list_words(in_docs):\n",
        "    return [x for y in in_docs for x in y]\n",
        "\n",
        "words_tr = create_list_words(docs_tr)\n",
        "words_ts = create_list_words(docs_ts)\n",
        "words_ts_h1 = create_list_words(docs_ts_h1)\n",
        "words_ts_h2 = create_list_words(docs_ts_h2)\n",
        "words_va = create_list_words(docs_va)\n",
        "\n",
        "print('  len(words_tr): ', len(words_tr))\n",
        "print('  len(words_ts): ', len(words_ts))\n",
        "print('  len(words_ts_h1): ', len(words_ts_h1))\n",
        "print('  len(words_ts_h2): ', len(words_ts_h2))\n",
        "print('  len(words_va): ', len(words_va))\n",
        "\n",
        "# Get doc indices\n",
        "print('getting doc indices...')\n",
        "\n",
        "def create_doc_indices(in_docs):\n",
        "    aux = [[j for i in range(len(doc))] for j, doc in enumerate(in_docs)]\n",
        "    return [int(x) for y in aux for x in y]\n",
        "\n",
        "doc_indices_tr = create_doc_indices(docs_tr)\n",
        "doc_indices_ts = create_doc_indices(docs_ts)\n",
        "doc_indices_ts_h1 = create_doc_indices(docs_ts_h1)\n",
        "doc_indices_ts_h2 = create_doc_indices(docs_ts_h2)\n",
        "doc_indices_va = create_doc_indices(docs_va)\n",
        "\n",
        "print('  len(np.unique(doc_indices_tr)): {} [this should be {}]'.format(len(np.unique(doc_indices_tr)), len(docs_tr)))\n",
        "print('  len(np.unique(doc_indices_ts)): {} [this should be {}]'.format(len(np.unique(doc_indices_ts)), len(docs_ts)))\n",
        "print('  len(np.unique(doc_indices_ts_h1)): {} [this should be {}]'.format(len(np.unique(doc_indices_ts_h1)), len(docs_ts_h1)))\n",
        "print('  len(np.unique(doc_indices_ts_h2)): {} [this should be {}]'.format(len(np.unique(doc_indices_ts_h2)), len(docs_ts_h2)))\n",
        "print('  len(np.unique(doc_indices_va)): {} [this should be {}]'.format(len(np.unique(doc_indices_va)), len(docs_va)))\n",
        "\n",
        "# Number of documents in each set\n",
        "n_docs_tr = len(docs_tr)\n",
        "n_docs_ts = len(docs_ts)\n",
        "n_docs_ts_h1 = len(docs_ts_h1)\n",
        "n_docs_ts_h2 = len(docs_ts_h2)\n",
        "n_docs_va = len(docs_va)\n",
        "\n",
        "# Remove unused variables\n",
        "del docs_tr\n",
        "del docs_ts\n",
        "del docs_ts_h1\n",
        "del docs_ts_h2\n",
        "del docs_va\n",
        "\n",
        "# Create bow representation\n",
        "print('creating bow representation...')\n",
        "\n",
        "def create_bow(doc_indices, words, n_docs, vocab_size):\n",
        "    return sparse.coo_matrix(([1]*len(doc_indices),(doc_indices, words)), shape=(n_docs, vocab_size)).tocsr()\n",
        "\n",
        "bow_tr = create_bow(doc_indices_tr, words_tr, n_docs_tr, len(vocab))\n",
        "bow_ts = create_bow(doc_indices_ts, words_ts, n_docs_ts, len(vocab))\n",
        "bow_ts_h1 = create_bow(doc_indices_ts_h1, words_ts_h1, n_docs_ts_h1, len(vocab))\n",
        "bow_ts_h2 = create_bow(doc_indices_ts_h2, words_ts_h2, n_docs_ts_h2, len(vocab))\n",
        "bow_va = create_bow(doc_indices_va, words_va, n_docs_va, len(vocab))\n",
        "\n",
        "del words_tr\n",
        "del words_ts\n",
        "del words_ts_h1\n",
        "del words_ts_h2\n",
        "del words_va\n",
        "del doc_indices_tr\n",
        "del doc_indices_ts\n",
        "del doc_indices_ts_h1\n",
        "del doc_indices_ts_h2\n",
        "del doc_indices_va\n",
        "\n",
        "# Write files for LDA C++ code\n",
        "def write_lda_file(filename, timestamps_in, time_list_in, bow_in):\n",
        "    idxSort = np.argsort(timestamps_in)\n",
        "    \n",
        "    with open(filename, \"w\") as f:\n",
        "        for row in idxSort:\n",
        "            x = bow_in.getrow(row)\n",
        "            n_elems = x.count_nonzero()\n",
        "            f.write(str(n_elems))\n",
        "            if(n_elems != len(x.indices) or n_elems != len(x.data)):\n",
        "                raise ValueError(\"[ERR] THIS SHOULD NOT HAPPEN\")\n",
        "            for ii, dd in zip(x.indices, x.data):\n",
        "                f.write(' ' + str(ii) + ':' + str(dd))\n",
        "            f.write('\\n')\n",
        "            \n",
        "    with open(filename.replace(\"-mult\", \"-seq\"), \"w\") as f:\n",
        "        f.write(str(len(time_list_in)) + '\\n')\n",
        "        for idx_t, _ in enumerate(time_list_in):\n",
        "            n_elem = len([t for t in timestamps_in if t==idx_t])\n",
        "            f.write(str(n_elem) + '\\n')\n",
        "            \n",
        "\n",
        "path_save = './min_df_' + str(min_df) + '/'\n",
        "if not os.path.isdir(path_save):\n",
        "    os.system('mkdir -p ' + path_save)\n",
        "\n",
        "# Write files for LDA C++ code\n",
        "print('saving LDA files for C++ code...')\n",
        "write_lda_file(path_save + 'dtm_tr-mult.dat', timestamps_tr, time_list, bow_tr)\n",
        "write_lda_file(path_save + 'dtm_ts-mult.dat', timestamps_ts, time_list, bow_ts)\n",
        "write_lda_file(path_save + 'dtm_ts_h1-mult.dat', timestamps_ts, time_list, bow_ts_h1)\n",
        "write_lda_file(path_save + 'dtm_ts_h2-mult.dat', timestamps_ts, time_list, bow_ts_h2)\n",
        "write_lda_file(path_save + 'dtm_va-mult.dat', timestamps_va, time_list, bow_va)\n",
        "\n",
        "# Also write the vocabulary and timestamps\n",
        "with open(path_save + 'vocab.txt', \"w\") as f:\n",
        "    for v in vocab:\n",
        "        f.write(v + '\\n')\n",
        "\n",
        "with open(path_save + 'timestamps.txt', \"w\") as f:\n",
        "    for t in time_list:\n",
        "        f.write(str(t) + '\\n')\n",
        "\n",
        "with open(path_save + 'vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "del vocab\n",
        "\n",
        "with open(path_save + 'timestamps.pkl', 'wb') as f:\n",
        "    pickle.dump(time_list, f)\n",
        "\n",
        "# Save timestamps alone\n",
        "savemat(path_save + 'bow_tr_timestamps', {'timestamps': timestamps_tr}, do_compression=True)\n",
        "savemat(path_save + 'bow_ts_timestamps', {'timestamps': timestamps_ts}, do_compression=True)\n",
        "savemat(path_save + 'bow_va_timestamps', {'timestamps': timestamps_va}, do_compression=True)\n",
        "\n",
        "# Split bow intro token/value pairs\n",
        "print('splitting bow intro token/value pairs and saving to disk...')\n",
        "\n",
        "def split_bow(bow_in, n_docs):\n",
        "    indices = [[w for w in bow_in[doc,:].indices] for doc in range(n_docs)]\n",
        "    counts = [[c for c in bow_in[doc,:].data] for doc in range(n_docs)]\n",
        "    return indices, counts\n",
        "\n",
        "bow_tr_tokens, bow_tr_counts = split_bow(bow_tr, n_docs_tr)\n",
        "savemat(path_save + 'bow_tr_tokens', {'tokens': bow_tr_tokens}, do_compression=True)\n",
        "savemat(path_save + 'bow_tr_counts', {'counts': bow_tr_counts}, do_compression=True)\n",
        "del bow_tr\n",
        "del bow_tr_tokens\n",
        "del bow_tr_counts\n",
        "\n",
        "bow_ts_tokens, bow_ts_counts = split_bow(bow_ts, n_docs_ts)\n",
        "savemat(path_save + 'bow_ts_tokens', {'tokens': bow_ts_tokens}, do_compression=True)\n",
        "savemat(path_save + 'bow_ts_counts', {'counts': bow_ts_counts}, do_compression=True)\n",
        "del bow_ts\n",
        "del bow_ts_tokens\n",
        "del bow_ts_counts\n",
        "\n",
        "bow_ts_h1_tokens, bow_ts_h1_counts = split_bow(bow_ts_h1, n_docs_ts_h1)\n",
        "savemat(path_save + 'bow_ts_h1_tokens', {'tokens': bow_ts_h1_tokens}, do_compression=True)\n",
        "savemat(path_save + 'bow_ts_h1_counts', {'counts': bow_ts_h1_counts}, do_compression=True)\n",
        "del bow_ts_h1\n",
        "del bow_ts_h1_tokens\n",
        "del bow_ts_h1_counts\n",
        "\n",
        "bow_ts_h2_tokens, bow_ts_h2_counts = split_bow(bow_ts_h2, n_docs_ts_h2)\n",
        "savemat(path_save + 'bow_ts_h2_tokens', {'tokens': bow_ts_h2_tokens}, do_compression=True)\n",
        "savemat(path_save + 'bow_ts_h2_counts', {'counts': bow_ts_h2_counts}, do_compression=True)\n",
        "del bow_ts_h2\n",
        "del bow_ts_h2_tokens\n",
        "del bow_ts_h2_counts\n",
        "\n",
        "bow_va_tokens, bow_va_counts = split_bow(bow_va, n_docs_va)\n",
        "savemat(path_save + 'bow_va_tokens', {'tokens': bow_va_tokens}, do_compression=True)\n",
        "savemat(path_save + 'bow_va_counts', {'counts': bow_va_counts}, do_compression=True)\n",
        "del bow_va\n",
        "del bow_va_tokens\n",
        "del bow_va_counts\n",
        "\n",
        "print('Data ready !!')\n",
        "print('*************')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S4CNh97pUkfG"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import torch \n",
        "import numpy as np\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "from bokeh.plotting import save\n",
        "from bokeh.models import HoverTool\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib \n",
        "\n",
        "tiny = 1e-6\n",
        "\n",
        "def _reparameterize(mu, logvar, num_samples):\n",
        "    \"\"\"Applies the reparameterization trick to return samples from a given q\"\"\"\n",
        "    std = torch.exp(0.5 * logvar) \n",
        "    bsz, zdim = logvar.size()\n",
        "    eps = torch.randn(num_samples, bsz, zdim).to(mu.device)\n",
        "    mu = mu.unsqueeze(0)\n",
        "    std = std.unsqueeze(0)\n",
        "    res = eps.mul_(std).add_(mu)\n",
        "    return res\n",
        "\n",
        "def log_gaussian(z, mu=None, logvar=None):\n",
        "    sz = z.size()\n",
        "    d = z.size(2)\n",
        "    bsz = z.size(1)\n",
        "    if mu is None or logvar is None:\n",
        "        mu = torch.zeros(bsz, d).to(z.device)\n",
        "        logvar = torch.zeros(bsz, d).to(z.device)\n",
        "    mu = mu.unsqueeze(0)\n",
        "    logvar = logvar.unsqueeze(0)\n",
        "    var = logvar.exp()\n",
        "    log_density = ((z - mu)**2 / (var+tiny)).sum(2) # b\n",
        "    log_det = logvar.sum(2) # b\n",
        "    log_density = log_density + log_det + d*np.log(2*np.pi)\n",
        "    return -0.5*log_density\n",
        "\n",
        "def logsumexp(x, dim=0):\n",
        "    d = torch.max(x, dim)[0]   \n",
        "    if x.dim() == 1:\n",
        "        return torch.log(torch.exp(x - d).sum(dim)) + d\n",
        "    else:\n",
        "        return torch.log(torch.exp(x - d.unsqueeze(dim).expand_as(x)).sum(dim) + tiny) + d\n",
        "\n",
        "def flatten_docs(docs): #to get words and doc_indices\n",
        "    words = [x for y in docs for x in y]\n",
        "    doc_indices = [[j for _ in doc] for j, doc in enumerate(docs)]\n",
        "    doc_indices = [x for y in doc_indices for x in y]\n",
        "    return words, doc_indices\n",
        "    \n",
        "def onehot(data, min_length):\n",
        "    return list(np.bincount(data, minlength=min_length))\n",
        "\n",
        "def nearest_neighbors(word, embeddings, vocab, num_words):\n",
        "    vectors = embeddings.cpu().numpy() \n",
        "    index = vocab.index(word)\n",
        "    query = embeddings[index].cpu().numpy() \n",
        "    ranks = vectors.dot(query).squeeze()\n",
        "    denom = query.T.dot(query).squeeze()\n",
        "    denom = denom * np.sum(vectors**2, 1)\n",
        "    denom = np.sqrt(denom)\n",
        "    ranks = ranks / denom\n",
        "    mostSimilar = []\n",
        "    [mostSimilar.append(idx) for idx in ranks.argsort()[::-1]]\n",
        "    nearest_neighbors = mostSimilar[:num_words]\n",
        "    nearest_neighbors = [vocab[comp] for comp in nearest_neighbors]\n",
        "    return nearest_neighbors\n",
        "\n",
        "def visualize(docs, _lda_keys, topics, theta):\n",
        "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
        "    # project to 2D\n",
        "    tsne_lda = tsne_model.fit_transform(theta)\n",
        "    colormap = []\n",
        "    for name, hex in matplotlib.colors.cnames.items():\n",
        "        colormap.append(hex)\n",
        "\n",
        "    colormap = colormap[:len(theta[0, :])]\n",
        "    colormap = np.array(colormap)\n",
        "\n",
        "    title = '20 newsgroups TE embedding V viz'\n",
        "    num_example = len(docs)\n",
        "\n",
        "    plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
        "                     title=title,\n",
        "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
        "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
        "\n",
        "    plt.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
        "                 color=colormap[_lda_keys][:num_example])\n",
        "    plt.show()\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def _fetch(path, name):\n",
        "    if name == 'train':\n",
        "        token_file = os.path.join(path, 'bow_tr_tokens')\n",
        "        count_file = os.path.join(path, 'bow_tr_counts')\n",
        "    elif name == 'valid':\n",
        "        token_file = os.path.join(path, 'bow_va_tokens')\n",
        "        count_file = os.path.join(path, 'bow_va_counts')\n",
        "    else:\n",
        "        token_file = os.path.join(path, 'bow_ts_tokens')\n",
        "        count_file = os.path.join(path, 'bow_ts_counts')\n",
        "    tokens = scipy.io.loadmat(token_file)['tokens'].squeeze()\n",
        "    counts = scipy.io.loadmat(count_file)['counts'].squeeze()\n",
        "    if name == 'test':\n",
        "        token_1_file = os.path.join(path, 'bow_ts_h1_tokens')\n",
        "        count_1_file = os.path.join(path, 'bow_ts_h1_counts')\n",
        "        token_2_file = os.path.join(path, 'bow_ts_h2_tokens')\n",
        "        count_2_file = os.path.join(path, 'bow_ts_h2_counts')\n",
        "        tokens_1 = scipy.io.loadmat(token_1_file)['tokens'].squeeze()\n",
        "        counts_1 = scipy.io.loadmat(count_1_file)['counts'].squeeze()\n",
        "        tokens_2 = scipy.io.loadmat(token_2_file)['tokens'].squeeze()\n",
        "        counts_2 = scipy.io.loadmat(count_2_file)['counts'].squeeze()\n",
        "        return {'tokens': tokens, 'counts': counts, 'tokens_1': tokens_1, 'counts_1': counts_1, 'tokens_2': tokens_2,\n",
        "                'counts_2': counts_2}\n",
        "    return {'tokens': tokens, 'counts': counts}\n",
        "\n",
        "\n",
        "def _fetch_temporal(path, name):\n",
        "    if name == 'train':\n",
        "        token_file = os.path.join(path, 'bow_tr_tokens')\n",
        "        count_file = os.path.join(path, 'bow_tr_counts')\n",
        "        time_file = os.path.join(path, 'bow_tr_timestamps')\n",
        "    elif name == 'valid':\n",
        "        token_file = os.path.join(path, 'bow_va_tokens')\n",
        "        count_file = os.path.join(path, 'bow_va_counts')\n",
        "        time_file = os.path.join(path, 'bow_va_timestamps')\n",
        "    else:\n",
        "        token_file = os.path.join(path, 'bow_ts_tokens')\n",
        "        count_file = os.path.join(path, 'bow_ts_counts')\n",
        "        time_file = os.path.join(path, 'bow_ts_timestamps')\n",
        "    tokens = scipy.io.loadmat(token_file)['tokens'].squeeze()\n",
        "    counts = scipy.io.loadmat(count_file)['counts'].squeeze()\n",
        "    times = scipy.io.loadmat(time_file)['timestamps'].squeeze()\n",
        "    if name == 'test':\n",
        "        token_1_file = os.path.join(path, 'bow_ts_h1_tokens')\n",
        "        count_1_file = os.path.join(path, 'bow_ts_h1_counts')\n",
        "        token_2_file = os.path.join(path, 'bow_ts_h2_tokens')\n",
        "        count_2_file = os.path.join(path, 'bow_ts_h2_counts')\n",
        "        tokens_1 = scipy.io.loadmat(token_1_file)['tokens'].squeeze()\n",
        "        counts_1 = scipy.io.loadmat(count_1_file)['counts'].squeeze()\n",
        "        tokens_2 = scipy.io.loadmat(token_2_file)['tokens'].squeeze()\n",
        "        counts_2 = scipy.io.loadmat(count_2_file)['counts'].squeeze()\n",
        "        return {'tokens': tokens, 'counts': counts, 'times': times,\n",
        "                'tokens_1': tokens_1, 'counts_1': counts_1,\n",
        "                'tokens_2': tokens_2, 'counts_2': counts_2}\n",
        "    return {'tokens': tokens, 'counts': counts, 'times': times}\n",
        "\n",
        "\n",
        "def get_data(path, temporal=False):\n",
        "    ### load vocabulary\n",
        "    with open(os.path.join(path, 'vocab.pkl'), 'rb') as f:\n",
        "        vocab = pickle.load(f)\n",
        "\n",
        "    if not temporal:\n",
        "        train = _fetch(path, 'train')\n",
        "        valid = _fetch(path, 'valid')\n",
        "        test = _fetch(path, 'test')\n",
        "    else:\n",
        "        train = _fetch_temporal(path, 'train')\n",
        "        valid = _fetch_temporal(path, 'valid')\n",
        "        test = _fetch_temporal(path, 'test')\n",
        "\n",
        "    return vocab, train, valid, test\n",
        "\n",
        "\n",
        "def get_batch(tokens, counts, ind, vocab_size, temporal=False, times=None):\n",
        "    \"\"\"fetch input data by batch.\"\"\"\n",
        "    batch_size = len(ind)\n",
        "    data_batch = np.zeros((batch_size, vocab_size))\n",
        "    if temporal:\n",
        "        times_batch = np.zeros((batch_size,))\n",
        "    for i, doc_id in enumerate(ind):\n",
        "        doc = tokens[doc_id]\n",
        "        count = counts[doc_id]\n",
        "        if temporal:\n",
        "            timestamp = times[doc_id]\n",
        "            times_batch[i] = timestamp\n",
        "        L = count.shape[1]\n",
        "        if len(doc) == 1:\n",
        "            doc = [doc.squeeze()]\n",
        "            count = [count.squeeze()]\n",
        "        else:\n",
        "            doc = doc.squeeze()\n",
        "            count = count.squeeze()\n",
        "        if doc_id != -1:\n",
        "            for j, word in enumerate(doc):\n",
        "                data_batch[i, word] = count[j]\n",
        "    data_batch = torch.from_numpy(data_batch).float().to(device)\n",
        "    if temporal:\n",
        "        times_batch = torch.from_numpy(times_batch).to(device)\n",
        "        return data_batch, times_batch\n",
        "    return data_batch\n",
        "\n",
        "def get_rnn_input(tokens, counts, times, num_times, vocab_size, num_docs):\n",
        "    #(data_batch,times_batch, num_times, vocab_size):\n",
        "    ind = torch.randperm(num_docs).to(device)\n",
        "    data_batch, times_batch = get_batch(tokens, counts, ind, vocab_size, temporal=True, times=times)\n",
        "    rnn_input = torch.zeros(num_times, vocab_size).to(device)\n",
        "    cnt = torch.zeros(num_times, ).to(device)\n",
        "    for t in range(num_times):\n",
        "        tmp = (times_batch == t).nonzero()\n",
        "        docs = data_batch[tmp].squeeze().sum(0)\n",
        "        rnn_input[t] += docs\n",
        "        cnt[t] += tmp.shape[0]\n",
        "    rnn_input = rnn_input / cnt.unsqueeze(1)\n",
        "    return rnn_input\n",
        "\n",
        "# def get_rnn_input(tokens, counts, times, num_times, vocab_size, num_docs):\n",
        "#     indices = torch.randperm(num_docs)\n",
        "#     indices = torch.split(indices, 1000)\n",
        "#     rnn_input = torch.zeros(num_times, vocab_size).to(device)\n",
        "#     cnt = torch.zeros(num_times, ).to(device)\n",
        "#     for idx, ind in enumerate(indices):\n",
        "#         data_batch, times_batch = get_batch(tokens, counts, ind, vocab_size, temporal=True, times=times)\n",
        "#         for t in range(num_times):\n",
        "#             tmp = (times_batch == t).nonzero()\n",
        "#             docs = data_batch[tmp].squeeze().sum(0)\n",
        "#             rnn_input[t] += docs\n",
        "#             cnt[t] += len(tmp)\n",
        "#         if idx % 20 == 0:\n",
        "#             print('idx: {}/{}'.format(idx, len(indices)))\n",
        "#     rnn_input = rnn_input / cnt.unsqueeze(1)\n",
        "#     return rnn_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_odfEs3sUkfJ",
        "outputId": "e6c4a934-9235-44ba-ee0b-7486d573bd12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting vocabulary ...\n",
            "Getting training data ...\n",
            "Getting validation data ...\n",
            "Getting testing data ...\n"
          ]
        }
      ],
      "source": [
        "print('Getting vocabulary ...')\n",
        "data_file = os.path.join('./', 'min_df_{}'.format(100))\n",
        "vocab, train, valid, test = get_data(data_file, temporal=True)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 1. training data\n",
        "print('Getting training data ...')\n",
        "train_tokens = train['tokens']\n",
        "train_counts = train['counts']\n",
        "train_times = train['times']\n",
        "num_times = train_times.max()-train_times.min()+1#len(np.unique(train_times))\n",
        "num_docs_train = len(train_tokens)\n",
        "\n",
        "batch_size=1024\n",
        "test_ratio = 0.8\n",
        "train_size = int(np.floor(test_ratio * len(train_tokens)))\n",
        "test_size = int(np.floor(0.15*len(train_tokens)))\n",
        "#test_size = test_size-(test_size%batch_size)\n",
        "valid_size = len(train_tokens)-train_size-test_size\n",
        "\n",
        "\n",
        "# 2. dev set\n",
        "print('Getting validation data ...')\n",
        "valid_tokens = valid['tokens']\n",
        "valid_counts = valid['counts']\n",
        "valid_times = valid['times']\n",
        "num_docs_valid = len(valid_tokens)\n",
        "valid_rnn_inp = get_rnn_input(\n",
        "    valid_tokens, valid_counts, valid_times, num_times, vocab_size, valid_size).nan_to_num()\n",
        "\n",
        "# 3. test data\n",
        "print('Getting testing data ...')\n",
        "test_tokens = test['tokens']\n",
        "test_counts = test['counts']\n",
        "test_times = test['times']\n",
        "num_docs_test = len(test_tokens)\n",
        "test_rnn_inp = get_rnn_input(\n",
        "    test_tokens, test_counts, test_times, num_times, vocab_size, test_size).nan_to_num()\n",
        "\n",
        "train_rnn_inp = get_rnn_input(\n",
        "    train_tokens, train_counts, train_times, num_times, vocab_size, train_size).nan_to_num()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qm5gK32cUkfK"
      },
      "outputs": [],
      "source": [
        "train_cvz, train_ts = get_batch(\n",
        "            train_tokens, train_counts, torch.tensor(range(train_size)).to(device), vocab_size, temporal=True, times=train_times)\n",
        "valid_cvz, valid_ts = get_batch(\n",
        "            valid_tokens, valid_counts, torch.tensor(range(valid_size)).to(device), vocab_size, temporal=True, times=valid_times)\n",
        "test_cvz, test_ts = get_batch(\n",
        "            test_tokens, test_counts, torch.tensor(range(test_size)).to(device), vocab_size, temporal=True, times=test_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WoVSpkhBUkfK"
      },
      "outputs": [],
      "source": [
        "# batch_size=1024\n",
        "# test_ratio = 0.8\n",
        "# train_size = int(np.floor(test_ratio * len(cvz)))\n",
        "# test_size = int(np.floor(0.15*len(cvz)))\n",
        "# #test_size = test_size-(test_size%batch_size)\n",
        "# valid_size = len(cvz)-train_size-test_size\n",
        "\n",
        "# print(train_size, test_size, valid_size)\n",
        "\n",
        "# cvz = cvz.float().to(device)\n",
        "# ts = ts.to(device)\n",
        "\n",
        "# shuf_ind = torch.randperm(cvz.shape[0])\n",
        "# cvz = cvz[shuf_ind]\n",
        "# ts = ts[shuf_ind]\n",
        "\n",
        "# train_cvz, test_cvz, valid_cvz = torch.split(cvz, [train_size, test_size, valid_size])\n",
        "# train_ts,  test_ts,  valid_ts  = torch.split(ts,  [train_size, test_size, valid_size])\n",
        "# # shuffle\n",
        "# indexes = torch.randperm(train_cvz.shape[0])\n",
        "# train_cvz = train_cvz[indexes]\n",
        "# train_ts = train_ts[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsd-4I_PN91l"
      },
      "outputs": [],
      "source": [
        "from torch.distributions.constraints import positive\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    alpha = model.mu_q_alpha.clone().contiguous()    # KxTxL\n",
        "    alpha = alpha.permute(1, 0, 2)\n",
        "    beta = model.get_beta(alpha)\n",
        "    beta = beta[:,:,:-3]\n",
        "    cnt = 0\n",
        "    tc = 0\n",
        "    for time in range(0, beta.shape[0]):\n",
        "        beta_t = beta[time,:,:]\n",
        "        cnt+=1\n",
        "        tc+=get_topic_coherence(beta_t, cvz)\n",
        "    tc/=cnt\n",
        "    print(f'tc: {tc}')\n",
        "\n",
        "\n",
        "\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "# get index first\n",
        "# train_rnn_inp = get_rnn_inp(train_cvz.to(device), train_ts.to(device), len(times), train_cvz.shape[1])\n",
        "# test_rnn_inp = get_rnn_inp(test_cvz.to(device), test_ts.to(device), len(times), test_cvz.shape[1])\n",
        "# valid_rnn_inp = get_rnn_inp(valid_cvz.to(device), valid_ts.to(device), len(times), valid_cvz.shape[1])\n",
        "# define model\n",
        "model = TETM(vocab_size=cvz.shape[1],\n",
        "             num_topics=30,\n",
        "             num_times=len(times),\n",
        "             hidden=800,\n",
        "             dropout=0.0,\n",
        "             delta=0.005,\n",
        "             emb_type='NN',\n",
        "             useEmbedding=True,\n",
        "             trainEmbedding=True,\n",
        "             rho_size=300,\n",
        "             eta_size=128,\n",
        "             data_size=train_rnn_inp.shape[0]\n",
        "            )\n",
        "\n",
        "#print_top_words(beta[:,:,:-3],vocab)\n",
        "def _diversity_helper(beta, num_tops):\n",
        "    list_w = torch.zeros((int(beta.shape[0]), num_tops))\n",
        "    for k in range(int(beta.shape[0])):\n",
        "        gamma = beta[k, :]\n",
        "        top_words = gamma.argsort()[-num_tops:]\n",
        "        list_w[k, :] = top_words\n",
        "    list_w = list_w.reshape(-1)\n",
        "    n_unique = len(list_w.unique())\n",
        "    diversity = n_unique / (beta.shape[0] * num_tops)\n",
        "    return diversity\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "# print model parameters\n",
        "# count_parameters(model)\n",
        "print(model)\n",
        "\n",
        "num_epochs=1000\n",
        "bar = trange(num_epochs)\n",
        "\n",
        "# dataloader loop\n",
        "# TODO save the loss/batch-loss\n",
        "# - reconstruction loss\n",
        "recon_loss_trace = []\n",
        "# - kl-loss\n",
        "kl_loss_trace = []\n",
        "# - transformer loss\n",
        "trans_loss_trace = []\n",
        "# - combined loss, can be done with post-processing\n",
        "combined_loss_trace = []\n",
        "# - validation perplexity\n",
        "val_ppl_trace = []\n",
        "\n",
        "num_batches = int(math.ceil(train_cvz.shape[0] / batch_size))\n",
        "optim = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-6)\n",
        "for epoch in bar:\n",
        "    batch_recon_loss = []\n",
        "    batch_kl_loss = []\n",
        "    batch_trans_loss = []\n",
        "    for i in range(num_batches):\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        optim.zero_grad()\n",
        "\n",
        "        if (i + 1) * batch_size > len(train_cvz):\n",
        "            batch_docs = train_cvz[i * batch_size:, :]\n",
        "            time_batch = train_ts[i * batch_size:]\n",
        "        else:    \n",
        "            batch_docs = train_cvz[i * batch_size:(i + 1) * batch_size, :]\n",
        "            time_batch = train_ts[i * batch_size:(i + 1) * batch_size]\n",
        "        batch_docs = batch_docs.nan_to_num()\n",
        "        # normalize batch\n",
        "        sums = batch_docs.sum(1).unsqueeze(1)\n",
        "        normalized_data_batch = batch_docs #/ sums\n",
        "        # Calculate loss of transformer model\n",
        "        recon_loss, kl_alpha, kl_eta, kl_theta,kld_eta_gp = model(batch_docs, normalized_data_batch, time_batch, \n",
        "                                                       train_rnn_inp,len(train_cvz))\n",
        "        # scale the product\n",
        "        bsz = batch_docs.size(0)\n",
        "        #coeff = len(cvz) / bsz\n",
        "        kl_loss = recon_loss + kl_alpha + kl_theta + kl_eta - 0.5*kld_eta_gp\n",
        "        kl_loss = kl_loss.sum()\n",
        "        # optimizer\n",
        "        batch_loss = kl_loss # + recon_loss\n",
        "        bar.set_postfix(recon='{:.5e}'.format(recon_loss),\n",
        "                        alpha='{:.2e}'.format(kl_alpha),\n",
        "                        theta='{:.2e}'.format(kl_theta.sum()),\n",
        "                        eta='{:.2e}'.format(kl_eta.sum()))\n",
        "\n",
        "        # gradient step\n",
        "        batch_loss.backward()\n",
        "        optim.step()\n",
        "        batch_loss.item()\n",
        "#         batch_recon_loss.append(recon_loss.item())\n",
        "        batch_kl_loss.append(kl_loss.item())\n",
        "    # store the average loss\n",
        "#     recon_loss_trace.append(batch_recon_loss)\n",
        "    kl_loss_trace.append(batch_kl_loss)\n",
        "\n",
        " #   if epoch % 100 == 0 and epoch > 0:\n",
        "        # topic coherence\n",
        "#        evaluate(model)\n",
        "    if epoch> 0 and epoch % 980 == 0:\n",
        "        # KxTxL\n",
        "        alpha = model.get_alpha()[0]\n",
        "        beta = model.get_beta(alpha)\n",
        "        print(beta.shape)\n",
        "\n",
        "        cnt = 0\n",
        "        tc = 0\n",
        "        for time in range(0,beta.shape[0]):\n",
        "            beta_t = beta[time,:,:]\n",
        "            cnt+=1\n",
        "            tc_k=get_topic_coherence(beta_t, train_cvz)\n",
        "            print(tc_k)\n",
        "            tc+=tc_k\n",
        "\n",
        "        tc/=cnt\n",
        "        print(f'tc: {tc}')\n",
        "\n",
        "    model.eval()\n",
        "    sums = valid_cvz.sum(1).unsqueeze(1)\n",
        "    valid_cvz = valid_cvz.nan_to_num()\n",
        "    normalized_valid_batch = valid_cvz.nan_to_num() #/ sums\n",
        "    ppl = model.predict(valid_cvz, normalized_valid_batch, valid_ts.nan_to_num(), valid_rnn_inp.nan_to_num())\n",
        "    print(f'Validation perplexity: {ppl}')\n",
        "    val_ppl_trace.append(ppl)\n",
        "    # KxTxL\n",
        "    alpha = model.get_alpha()[0]\n",
        "    beta = model.get_beta(alpha)\n",
        "    td = 0\n",
        "    for t in range(beta.shape[0]):\n",
        "        d=_diversity_helper(beta[t],25)\n",
        "        td+=d\n",
        "    print(f'TD: {td/beta.shape[0]}')\n",
        "\n",
        "# test_ppl = 0\n",
        "# test_cnt = 0\n",
        "# for data in test_loader:\n",
        "#     d_batch, t_batch = cvz[data['index'] - 1, :], ts[data['index'] - 1]\n",
        "#     test_ppl += model.predict(d_batch.nan_to_num(), t_batch.nan_to_num(), train_rnn_inp.nan_to_num())\n",
        "#     test_cnt += 1\n",
        "# # perplexity\n",
        "# test_ppl /= test_cnt\n",
        "# print(f'Test perplpexity: {test_ppl}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqPmb8riN91t"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "print(test_cvz.shape)\n",
        "test_cvz = test_cvz.nan_to_num().float()  \n",
        "normalized_test_batch = test_cvz #/ sums\n",
        "ppl = model.predict(test_cvz, normalized_test_batch, test_ts, test_rnn_inp.nan_to_num())\n",
        "print(f'Validation perplexity: {ppl}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUYdcTnfN917"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, num_workers=1, shuffle=False)\n",
        "#test_rnn_inp = get_rnn_input(test_loader, len(ts.unique()),cvz.shape[1]).cuda().nan_to_num(0)\n",
        "print(d_batch, t_batch, len(dataset))\n",
        "    \n",
        "test_ppl = 0\n",
        "test_cnt = 0\n",
        "for data in test_loader:\n",
        "    d_batch, t_batch = cvz[data['index'] - 1, :].to(device), ts[data['index'] - 1].to(device)\n",
        "    test_rnn_inp = get_rnn_inp(d_batch, t_batch, len(ts.unique()),cvz.shape[1]).cuda().nan_to_num(0)\n",
        "    test_ppl += model.predict(d_batch, t_batch, test_rnn_inp)\n",
        "    test_cnt += 1\n",
        "# perplexity\n",
        "test_ppl /= test_cnt\n",
        "print(f'Test perplpexity: {test_ppl}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgD7S2NJN91-"
      },
      "source": [
        "Topic Coherence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlcEgEVbN91_"
      },
      "outputs": [],
      "source": [
        "# output the result\n",
        "def print_top_words(beta, feature_names, n_top_words=10):\n",
        "    for k in range(beta.shape[1]):\n",
        "        for t in range(0,beta.shape[0],5):\n",
        "            print(\n",
        "                (\"Topic #%d@time=%d: \" % (k,times[t]))\n",
        "                + \" \".join([feature_names[j]  for j in beta[t,k].argsort()[-n_top_words:]])\n",
        "            )\n",
        "\n",
        "print_top_words(beta[:,best_topics_rank,:-3],vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaSTvBNFN92A"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pkt')\n",
        "#Later to restore:\n",
        "# model.load_state_dict(torch.load(filepath))\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qty0AzdXN92A"
      },
      "outputs": [],
      "source": [
        "len(vocab)\n",
        "\n",
        "f = open(\"test.txt\",\"w\")\n",
        "f.write(' '.join(vocab))\n",
        "f.close()\n",
        "\n",
        "beta = model.get_beta_result()\n",
        "torch.save(beta, 'beta.pt')\n",
        "eta = model.get_eta_result()\n",
        "torch.save(eta, 'eta.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6E_ZTDbN92B"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMPU0fllUkfQ"
      },
      "outputs": [],
      "source": [
        "beta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TwE9DAxN92C"
      },
      "outputs": [],
      "source": [
        "data_file = os.path.join('./', 'min_df_{}'.format(100))\n",
        "vocab, train, valid, test = get_data(data_file, temporal=True)\n",
        "# KxTxL\n",
        "alpha = model.mu_q_alpha.clone().contiguous()\n",
        "alpha = alpha.permute(1,0,2)\n",
        "#alpha = model.get_alpha()[0]\n",
        "\n",
        "beta = model.get_beta(alpha)#, torch.arange(0,len(times)))\n",
        "# for bth in test_loader:\n",
        "#     t_index = torch.cat([t_index, bth['index']], dim=0)\n",
        "    \n",
        "t_bows = test_cvz#cvz[t_index - 1,:]\n",
        "t_times = test_ts#ts[t_index - 1]\n",
        "eta = model.get_eta_result()\n",
        "#eta, _ = model.get_mu(train_rnn_inp)\n",
        "#eta = eta.detach().cpu().numpy()\n",
        "theta, _ = model.get_theta(eta, t_bows, t_times)\n",
        "# select best 5 topics\n",
        "best_topics_rank = theta.sum(0).argsort()[-6:]\n",
        "# custom topics\n",
        "#best_topics_rank = theta.sum(0).argsort()[[0,1,9,13,16,19]].cuda().long()\n",
        "# select best 4 words from those topics\n",
        "best_vocab_rank = beta[:,best_topics_rank,:-3].sum(0).argsort(-1)[:,-5:]\n",
        "# check beta\n",
        "best_vocab = np.array(vocab)[best_vocab_rank.detach().cpu().numpy()]\n",
        "# \n",
        "#eta = eta.detach().cpu().numpy()\n",
        "eta = eta.softmax(-1).detach().cpu().numpy()\n",
        "theta = theta.detach().cpu().numpy()\n",
        "\n",
        "best_topics_rank, best_vocab_rank, best_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3OrBNxYsdEk"
      },
      "outputs": [],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HXdHe6GN92C"
      },
      "outputs": [],
      "source": [
        "# selected_rank = [[2,3,5],[0,1,2],[0,4,5],[1,4,5],[0,1,2],[1,3,4]]\n",
        "# selected_vocab_rank = best_vocab_rank.cpu().detach().numpy()[:,selected_rank]\n",
        "# selected_vocab_format = torch.tensor(np.array([selected_vocab_rank[i,i,:] for i in range(6)]))\n",
        "# selected_vocab = np.array(vocab)[selected_vocab_format]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTvhFiXnN92H"
      },
      "outputs": [],
      "source": [
        "# best_topics_rank = torch.tensor([0,1,9,13,16,17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAbKSYU7N92J"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(times[0],times[-1],times.shape[0])\n",
        "result = beta[:,best_topics_rank, :].squeeze(1)[:,:,best_vocab_rank].detach().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 8), dpi=80)\n",
        "\n",
        "for i in range(1,7):\n",
        "    plt.subplot(2,3,i)\n",
        "    plt.plot(x,result[:,i-1,i-1,:],label=best_vocab[i-1])\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('Years')\n",
        "    #plt.ylabel('Stack')\n",
        "\n",
        "plt.savefig('scatter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUxXhhsLN92J"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKmWz0ydUkfZ"
      },
      "outputs": [],
      "source": [
        "test_ts.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G0t38--N92K"
      },
      "outputs": [],
      "source": [
        "best_topics_rank.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHuItrK5N92L"
      },
      "outputs": [],
      "source": [
        "model.decoder.fcrho.weight().shape, theta.shape\n",
        "rho = model.decoder.fcrho.weight().detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtt5qSnfN92L"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "from bokeh.plotting import save\n",
        "from bokeh.models import HoverTool\n",
        "\n",
        "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
        "# project to 2D\n",
        "tsne_lda = tsne_model.fit_transform(theta)\n",
        "colormap = []\n",
        "for name, hex in matplotlib.colors.cnames.items():\n",
        "    colormap.append(hex)\n",
        "\n",
        "colormap = colormap[:len(theta[0, :])]\n",
        "colormap = np.array(colormap)\n",
        "title = '20 newsgroups TE embedding V viz'\n",
        "plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
        "                 title=title,\n",
        "                 tools=\"pan,wheel_zoom,box_zoom,reset,hover\",\n",
        "                 x_axis_type=None, y_axis_type=None, min_border=1)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
        "                    color=colormap[theta.argsort(-1)[:,-1]%148])\n",
        "plt.savefig('tsne1.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcC8QPktN92M"
      },
      "outputs": [],
      "source": [
        "s = lambda x: \"#Topic: \"+str(x)\n",
        "list(map(s, best_topics_rank.detach().cpu().numpy().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EHvz5eN92M"
      },
      "outputs": [],
      "source": [
        "s = list(map(\" \".join, best_vocab))\n",
        "# s = ['Topic 0: Graph',\n",
        "#     'Topic 1: Cognitive Science',\n",
        "#     'Topic 9: Embeddings',\n",
        "#     'Topic 13: Visual & Signaling',\n",
        "#     'Topic 16: Bayesian Statistics',\n",
        "#     'Topic 17: Decision Theory',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAUx-mneN92N"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# time range\n",
        "x = np.linspace(times[0],times[-1],times.shape[0])\n",
        "# select the (topic, topic-words)\n",
        "# topic word vocab\n",
        "plt.figure(figsize=(12,8))\n",
        "for i in range(0,6):\n",
        "    plt.plot(x, eta.T[best_topics_rank.detach().cpu().numpy()[i],:], \n",
        "              labels=best_vocab)\n",
        "             #label=s[i])\n",
        "# plt.stackplot(x, eta.T[best_topics_rank.detach().cpu().numpy(),:], \n",
        "#               labels=best_vocab)\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Year')\n",
        "#plt.ylabel('Stack')\n",
        "plt.title('Topic representation over time')\n",
        "plt.savefig('topic_scatter.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUJjrj-JN92P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# time range\n",
        "x = np.linspace(times[0],times[-1],times.shape[0])\n",
        "# select the (topic, topic-words)\n",
        "# topic word vocab\n",
        "plt.figure(figsize=(12,8))\n",
        "res = pd.DataFrame(eta.T[best_topics_rank.detach().cpu().numpy(),:].T).rolling(window=5).mean()#.plot(label=\"20SMA\", legend=True)\n",
        "custom_title = ['Theoretic bound','Latent variable model', 'Neural networks', 'Graph Theory', 'Bayesian statistics','Classification']\n",
        "plt.stackplot(x, res.T,labels=custom_title)\n",
        "#plt.stackplot(x, eta.T[best_topics_rank.detach().cpu().numpy(),:],labels=best_vocab)\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Year')\n",
        "#plt.ylabel('Stack')\n",
        "plt.title('Topic representation over time')\n",
        "plt.savefig('topic_stack_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekhfoxl1Ukfc"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(eta.T[best_topics_rank.detach().cpu().numpy(),:].T).rolling(window=5).mean().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiziLWpDUkfd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAWI6zkHtd0W"
      },
      "outputs": [],
      "source": [
        "!pip install pyvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXzCaq1Ftmhs"
      },
      "outputs": [],
      "source": [
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plt.figure(figsize=(16,12))\n",
        "#sb.heatmap(pd.DataFrame(filtered_beta.T).corr(),vmin=-1,annot=True)\n",
        "sb.heatmap(pd.DataFrame(model.L_Omega[30].cpu().numpy()),vmin=-1,annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_q-6hBlwFdL"
      },
      "outputs": [],
      "source": [
        "def get_top_words(k, top=5):\n",
        "  # KxTxL\n",
        "  alpha = model.mu_q_alpha.clone().contiguous()\n",
        "  alpha = alpha.permute(1,0,2)\n",
        "  #alpha = model.get_alpha()[0]\n",
        "\n",
        "  beta = model.get_beta(alpha, torch.arange(0,len(times)))\n",
        "  # select best 4 words from those topics\n",
        "  best_vocab_rank = beta[:,k,:-3].sum(0).argsort(-1)[-top:]\n",
        "  # check beta\n",
        "  best_vocab = np.array(vocab)[best_vocab_rank.detach().cpu().numpy()]\n",
        "  return best_vocab.tolist()\n",
        "\n",
        "get_top_words(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfxGVrtCwfoY"
      },
      "outputs": [],
      "source": [
        "li = model.L_Omega[0][10].cpu().tolist()\n",
        "li.pop(10)\n",
        "len(li)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnqlwbbztXV5"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "num_topics = 30\n",
        "time_t = 26\n",
        "# Let's visualize the result\n",
        "g = Network(width=800, height=800, font_color=\"#333\")\n",
        "correl = model.L_Omega[time_t].reshape([-1]).cpu().tolist()\n",
        "correl.sort()\n",
        "top_tenth = num_topics * (num_topics - 1) // 10\n",
        "top_tenth = correl[-num_topics - top_tenth]\n",
        "\n",
        "for k in range(num_topics):\n",
        "    label = \"#{}\".format(k)\n",
        "    title= ' '.join(word for word in get_top_words(k, top=6))\n",
        "    print('Topic', label, title)\n",
        "    g.add_node(k, label=label, title=title, shape='ellipse')\n",
        "    li = model.L_Omega[time_t][k].cpu().tolist()\n",
        "    li.pop(k)\n",
        "    for l, correlation in zip(range(k - 1), li):\n",
        "        if correlation < top_tenth: continue\n",
        "        g.add_edge(k, l, value=float(correlation), title='{:.02}'.format(correlation))\n",
        "\n",
        "g.barnes_hut(gravity=-1000, spring_length=20)\n",
        "g.show_buttons()\n",
        "g.show(\"topic_network.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IlegMYYN92Q"
      },
      "outputs": [],
      "source": [
        "eta = torch.from_numpy(eta).softmax(-1).detach().numpy()\n",
        "\n",
        "\n",
        "x = np.linspace(times[0],times[-1],times.shape[0])\n",
        "\n",
        "plt.figure(figsize=(12, 8), dpi=80)\n",
        "\n",
        "for i in range(1,21):\n",
        "    plt.subplot(5,4,i)\n",
        "    plt.plot(x,eta[:,i-1])\n",
        "    #plt.legend(loc='upper left')\n",
        "    #plt.xlabel('Years')\n",
        "    #plt.ylabel('Stack')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEfxt30TN92R"
      },
      "outputs": [],
      "source": [
        "data_file = os.path.join('./', 'min_df_{}'.format(100))\n",
        "vocab, train, valid, test = get_data(data_file, temporal=True)\n",
        "vocab, count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIXo_KirN92R"
      },
      "outputs": [],
      "source": [
        "# KxTxL\n",
        "alpha = model.mu_q_alpha.clone().contiguous()\n",
        "alpha = alpha.permute(1,0,2)\n",
        "#alpha = model.get_alpha()[0]\n",
        "beta = model.get_beta(alpha)\n",
        "print(beta.shape)\n",
        "\n",
        "cnt = 0\n",
        "tc = 0\n",
        "#beta = beta[:,:,:-3]\n",
        "for time in range(0,beta.shape[0]):\n",
        "    beta_t = beta[time,:,:]\n",
        "    cnt+=1\n",
        "    tc_k=get_topic_coherence(beta_t, valid_cvz)\n",
        "    print(tc_k)\n",
        "    tc+=tc_k\n",
        "\n",
        "tc/=cnt\n",
        "print(f'tc: {tc}')\n",
        "\n",
        "#print_top_words(beta[:,:,:-3],vocab)\n",
        "def _diversity_helper(beta, num_tops):\n",
        "    list_w = torch.zeros((int(beta.shape[0]), num_tops))\n",
        "    for k in range(int(beta.shape[0])):\n",
        "        gamma = beta[k, :]\n",
        "        top_words = gamma.argsort()[-num_tops:]\n",
        "        list_w[k, :] = top_words\n",
        "    list_w = list_w.reshape(-1)\n",
        "    n_unique = len(list_w.unique())\n",
        "    diversity = n_unique / (beta.shape[0] * num_tops)\n",
        "    return diversity\n",
        "\n",
        "td = 0\n",
        "for t in range(beta.shape[0]):\n",
        "    d=_diversity_helper(beta[t],25)\n",
        "    td+=d\n",
        "    print(d)\n",
        "print(f'TD: {td/beta.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_oKkCeBN92S"
      },
      "outputs": [],
      "source": [
        "cvz.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0RgYZSnN92U"
      },
      "outputs": [],
      "source": [
        "# note that this helper function does three different things:\n",
        "# (i) plots the observed data;\n",
        "# (ii) plots the predictions from the learned GP after conditioning on data;\n",
        "# (iii) plots samples from the GP prior (with no conditioning on observed data)\n",
        "\n",
        "def plot(plot_observed_data=False, plot_predictions=False, n_prior_samples=0,\n",
        "         model=None, kernel=None, n_test=500):\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    if plot_observed_data:\n",
        "        plt.plot(X.numpy(), y.numpy(), 'kx')\n",
        "    if plot_predictions:\n",
        "        Xtest = torch.linspace(-0.5, 5.5, n_test)  # test inputs\n",
        "        # compute predictive mean and variance\n",
        "        with torch.no_grad():\n",
        "            if type(model) == gp.models.VariationalSparseGP:\n",
        "                mean, cov = model(Xtest, full_cov=True)\n",
        "            else:\n",
        "                mean, cov = model(Xtest, full_cov=True, noiseless=False)\n",
        "        sd = cov.diag().sqrt()  # standard deviation at each input point x\n",
        "        plt.plot(Xtest.numpy(), mean.numpy(), 'r', lw=2)  # plot the mean\n",
        "        plt.fill_between(Xtest.numpy(),  # plot the two-sigma uncertainty about the mean\n",
        "                         (mean - 2.0 * sd).numpy(),\n",
        "                         (mean + 2.0 * sd).numpy(),\n",
        "                         color='C0', alpha=0.3)\n",
        "    if n_prior_samples > 0:  # plot samples from the GP prior\n",
        "        Xtest = torch.linspace(-0.5, 5.5, n_test)  # test inputs\n",
        "        noise = (model.noise if type(model) != gp.models.VariationalSparseGP\n",
        "                 else model.likelihood.variance)\n",
        "        cov = kernel.forward(Xtest) + noise.expand(n_test).diag()\n",
        "        samples = dist.MultivariateNormal(torch.zeros(n_test), covariance_matrix=cov)\\\n",
        "                      .sample(sample_shape=(n_prior_samples,))\n",
        "        plt.plot(Xtest.numpy(), samples.numpy().T, lw=2, alpha=0.4)\n",
        "\n",
        "    plt.xlim(-0.5, 5.5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of dtm-tir-dtm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}